Online Learning Feedback and Course Evaluation System — Parallel & Distributed DB Lab (Postgraduate)

# Purpose

Design, implement and analyze a small distributed DB environment. Demonstrate fragmentation, remote querying, 
2PC simulation, parallel execution tests, concurrency control, recovery, ETL/parallel loading, architecture design, 
query optimization, and comparative benchmarking.

# Table of Contents

Environment & assumptions
Schema & sample data (centralized)

Task 1 — Distributed schema / fragmentation
Task 2 — Create and use database links (postgres_fdw)
Task 3 — Parallel query execution (EXPLAIN ANALYZE and settings)
Task 4 — Two-phase commit simulation (PREPARE TRANSACTION)
Task 5 — Distributed rollback and recovery (simulate failure & resolve)
Task 6 — Distributed concurrency control (locks & pg_locks)
Task 7 — Parallel data loading / ETL simulation (generate large data + parallel agg)
Task 8 — Three-tier architecture diagram & explanation
Task 9 — Distributed query optimization (EXPLAIN, use_remote_estimate)
Task 10 — Performance benchmark (centralized vs parallel vs distributed)

1. Centralized schema & sample data (run once)

Below is the main schema and sample data. Run as a single SQL file.

# Clean start (use with caution; for lab environment only)
DROP SCHEMA IF EXISTS node_a CASCADE;
DROP SCHEMA IF EXISTS node_b CASCADE;
DROP TABLE IF EXISTS EvaluationSummary, Feedback, Student, Course, Instructor, Department CASCADE;

# Create tables (centralized)
CREATE TABLE Department (
  DeptID SERIAL PRIMARY KEY,
  DeptName TEXT NOT NULL,
  FacultyHead TEXT,
  Contact TEXT
);

CREATE TABLE Instructor (
  InstructorID SERIAL PRIMARY KEY,
  FullName TEXT NOT NULL,
  DeptID INT REFERENCES Department(DeptID) ON DELETE SET NULL,
  Email TEXT,
  Experience INT CHECK (Experience >= 0)
);

CREATE TABLE Course (
  CourseID SERIAL PRIMARY KEY,
  InstructorID INT REFERENCES Instructor(InstructorID),
  DeptID INT REFERENCES Department(DeptID),
  Title TEXT NOT NULL,
  CreditHours INT CHECK (CreditHours > 0),
  Level TEXT
);

CREATE TABLE Student (
  StudentID SERIAL PRIMARY KEY,
  FullName TEXT,
  Gender TEXT CHECK (Gender IN ('Male','Female')),
  Email TEXT,
  YearOfStudy INT CHECK (YearOfStudy BETWEEN 1 AND 5)
);

CREATE TABLE Feedback (
  FeedbackID SERIAL PRIMARY KEY,
  StudentID INT REFERENCES Student(StudentID) ON DELETE CASCADE,
  CourseID INT REFERENCES Course(CourseID) ON DELETE CASCADE,
  Rating INT CHECK (Rating BETWEEN 1 AND 5),
  Comment TEXT,
  DateSubmitted DATE DEFAULT CURRENT_DATE
);

CREATE TABLE EvaluationSummary (
  SummaryID SERIAL PRIMARY KEY,
  CourseID INT UNIQUE REFERENCES Course(CourseID),
  AvgRating NUMERIC(3,2),
  TotalResponses INT,
  EvaluationDate DATE DEFAULT CURRENT_DATE
);

# Insert sample data
INSERT INTO Department (DeptName, FacultyHead, Contact) VALUES
('Computer Science','Dr. Alice','alice@uni.edu'),
('Business','Dr. Ben','ben@uni.edu'),
('Education','Dr. Carol','carol@uni.edu');

INSERT INTO Instructor (FullName, DeptID, Email, Experience) VALUES
('John Doe',1,'john@uni.edu',5),
('Jane Smith',1,'jane@uni.edu',8),
('Robert Brown',2,'robert@uni.edu',10),
('Emily White',3,'emily@uni.edu',6),
('Michael Green',2,'michael@uni.edu',3);

INSERT INTO Course (InstructorID, DeptID, Title, CreditHours, Level) VALUES
(1,1,'Database Systems',3,'Undergraduate'),
(2,1,'Machine Learning',4,'Postgraduate'),
(3,2,'Business Analytics',3,'Undergraduate'),
(4,3,'Educational Psychology',3,'Undergraduate'),
(5,2,'Marketing Strategies',2,'Undergraduate');

INSERT INTO Student (FullName, Gender, Email, YearOfStudy) VALUES
('Alice Johnson','Female','alicej@uni.edu',2),
('Brian Lee','Male','brianl@uni.edu',3),
('Carla Kim','Female','carlak@uni.edu',1),
('David Chan','Male','davidc@uni.edu',4),
('Eva Thomas','Female','evat@uni.edu',2),
('Frank Okoro','Male','franko@uni.edu',3),
('Grace Liu','Female','gracel@uni.edu',4),
('Henry Adams','Male','henrya@uni.edu',1),
('Ivy Njoroge','Female','ivyn@uni.edu',5),
('James Phiri','Male','jamesp@uni.edu',2);

INSERT INTO Feedback (StudentID, CourseID, Rating, Comment) VALUES
(1,1,5,'Excellent course!'),
(2,1,4,'Very informative'),
(3,2,3,'Good but challenging'),
(4,3,5,'Loved it!'),
(5,4,2,'Too basic'),
(6,5,4,'Interesting'),
(7,3,4,'Well structured'),
(8,2,5,'Highly engaging'),
(9,4,3,'Average'),
(10,1,4,'Good explanations');

# compute initial evaluation summary
INSERT INTO EvaluationSummary (CourseID, AvgRating, TotalResponses)
SELECT c.CourseID, ROUND(AVG(f.Rating),2), COUNT(*)
FROM Course c
JOIN Feedback f ON c.CourseID = f.CourseID
GROUP BY c.CourseID
ON CONFLICT (CourseID) DO UPDATE
SET AvgRating = EXCLUDED.AvgRating,
    TotalResponses = EXCLUDED.TotalResponses,
    EvaluationDate = CURRENT_DATE;

    
# TASK 2 — Create and Use Database Links (postgres_fdw) (2 marks)

Goal: Simulate DB links between Node_A and Node_B using postgres_fdw.
Steps (single-instance simulation)

Enable extension.
Create a foreign server that points to same instance (or remote instance if available).
Create user mapping and foreign tables or IMPORT FOREIGN SCHEMA.

# Enable FDW extension
CREATE EXTENSION IF NOT EXISTS postgres_fdw;

# Create a foreign server (pointing to same database for simulation; in real lab point to other instance)
# Replace host/port/dbname/user/password appropriately when using real remote DB.
CREATE SERVER node_b_server FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host 'localhost', dbname 'your_dbname', port '5432');

# Create user mapping for current role (adjust username/password if needed)
CREATE USER MAPPING FOR CURRENT_USER SERVER node_b_server OPTIONS (user 'your_pg_user', password 'your_password');

# Example: create a foreign table proxy (for demonstration use, map to node_b.course_b)
# First ensure schema qualification is correct: node_b.course_b exists in same DB. In real remote server you would IMPORT.
CREATE FOREIGN TABLE IF NOT EXISTS remote_course_b (
  courseid integer,
  instructorid integer,
  deptid integer,
  title text,
  credithours integer,
  level text
) SERVER node_b_server OPTIONS (schema_name 'node_b', table_name 'course_b');

# Now do a remote SELECT (acts like DB link): select from foreign table
SELECT * FROM remote_course_b LIMIT 5;

# Distributed join: join local node_a and remote node_b via FDW proxy
SELECT a.title AS local_course, b.title AS remote_course
FROM node_a.course_a a
JOIN remote_course_b b ON a.deptid = b.deptid
LIMIT 20;

TASK 3 — Parallel Query Execution (2 marks)

Goal: Compare serial vs parallel execution for a large table.
Prepare a large table for meaningful parallelism

# Create a large synthetic table for testing (many rows)
DROP TABLE IF EXISTS big_events;
CREATE TABLE big_events AS
SELECT
  generate_series(1,1000000) AS id,
  (random()*10)::int AS rating,
  md5(random()::text) AS payload,
  (now() - (random() * interval '365 days'))::date AS evdate;

# Create an index to support aggregates if needed
CREATE INDEX idx_bigevents_evdate ON big_events(evdate);
ANALYZE big_events;

Serial vs Parallel: measure with EXPLAIN ANALYZE

Set max_parallel_workers_per_gather and test.

# Serial run: disable parallel gather
SET LOCAL max_parallel_workers_per_gather = 0;
EXPLAIN (ANALYZE, BUFFERS, TIMING) SELECT avg(rating) FROM big_events WHERE evdate > now() - interval '180 days';

# Parallel run: enable parallel workers (e.g., 4)
SET LOCAL max_parallel_workers_per_gather = 4;
EXPLAIN (ANALYZE, BUFFERS, TIMING) SELECT avg(rating) FROM big_events WHERE evdate > now() - interval '180 days';

TASK 4 — Two-Phase Commit Simulation (PREPARE TRANSACTION) (2 marks)

Goal: Simulate distributed transaction commit across two nodes.
PostgreSQL support: PREPARE TRANSACTION / COMMIT PREPARED implements 2PC. It requires separate sessions 
(or separate connections). Example below uses two separate DB connections; in a single script we show the SQL 
that must be run in two sessions.

# connection A
# Session A: begin work on node_a (or DB A)
BEGIN;
INSERT INTO node_a.course_a (courseid, instructorid, deptid, title, credithours, level)
VALUES (999999, 1, 1, '2PC Test Course A', 1, 'Test');

# Prepare transaction
PREPARE TRANSACTION 'tx_a_1';
 Do NOT COMMIT here; leave prepared

 # connection B
 # Session B: begin work on node_b (or DB B)
BEGIN;
INSERT INTO node_b.course_b (courseid, instructorid, deptid, title, credithours, level)
VALUES (999998, 4, 3, '2PC Test Course B', 2, 'Test');

# Prepare transaction
PREPARE TRANSACTION 'tx_b_1';

# Check prepared transactions
SELECT gid, prepared, owner, database FROM pg_prepared_xacts;

TASK 5 — Distributed Rollback and Recovery (2 marks)

Goal: Simulate a failure after PREPARE and resolve dangling prepared transactions.
Simulate network failure during 2PC
Start Session A & Session B, run PREPARE TRANSACTION. Then forcibly close one session or shut down one node (simulate by killing session or turning off server).
The other node will have a prepared transaction waiting.

Resolve (example)
# List dangling prepared transactions
SELECT * FROM pg_prepared_xacts;

# Force rollback (if decision or recovery needed)
ROLLBACK PREPARED 'tx_a_1';

# Or if committing after recovery:
COMMIT PREPARED 'tx_a_1';

TASK 6 — Distributed Concurrency Control (locks) (2 marks)

Goal: Demonstrate lock conflict from two sessions updating same record and inspect lock info.
# big staging table and aggregate with parallel worker

# Create big_staging using generate_series (many rows)
DROP TABLE IF EXISTS big_staging;
CREATE TABLE big_staging AS
SELECT
  generate_series(1,2000000) AS id,
  (random()*5)::int AS rating,
  md5(random()::text) AS payload,
  now()::date - (random()*365)::int AS evdate;

ANALYZE big_staging;

# Parallel aggregate (enable parallel)
SET LOCAL max_parallel_workers_per_gather = 6;
EXPLAIN (ANALYZE, BUFFERS, TIMING) 
SELECT evdate, COUNT(*) AS cnt, AVG(rating) AS avg_rating
FROM big_staging
GROUP BY evdate
ORDER BY evdate DESC
LIMIT 10;

TASK 8 — Three-Tier Client–Server Architecture Design 
Goal: Present the three-tier architecture and explain interactions

[Presentation Layer]  <--->  [Application Layer (API / Backend)]  <--->  [Database Layer (node_a, node_b)]
    (Web UI / Mobile)           (REST API / Business logic)           (Postgres primary + FDW remote)


Flow:

UI sends requests to Application Server (e.g., Node.js/Python).
App server runs business logic and issues SQL. For distributed queries, it uses FDW or coordinates transactions across nodes.
DB layer: Node_A (local) stores CS and Business fragments; Node_B stores Education fragment.
 App server can use 2PC (PREPARE/COMMIT PREPARED) for distributed transactions.

 TASK 9 — Distributed Query Optimization (EXPLAIN + FDW tuning) (2 marks)
Goal: Use EXPLAIN (ANALYZE) and show how FDW planner estimates and options affect planning and data movement.

# EXPLAINATION  for distributed join
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT a.title AS a_title, b.title AS b_title
FROM node_a.course_a a
JOIN remote_course_b b ON a.deptid = b.deptid
WHERE a.title ILIKE '%Database%';

TASK 10 — Performance Benchmark & Report 
Goal: Run a complex query in three ways — centralized, parallel, distributed — collect times and I/O, and analyze.

# complex query (joins + aggregation)

EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT d.deptname, c.title, COUNT(f.feedbackid) AS responses, ROUND(AVG(f.rating),2) AS avg_rating
FROM Department d
JOIN Course c ON d.deptid = c.deptid
JOIN Feedback f ON c.courseid = f.courseid
GROUP BY d.deptname, c.title
ORDER BY avg_rating DESC
LIMIT 10;

# Parallel: enable parallel gather
SET LOCAL max_parallel_workers_per_gather = 6;
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT d.deptname, c.title, COUNT(f.feedbackid) AS responses, ROUND(AVG(f.rating),2) AS avg_rating
FROM Department d
JOIN Course c ON d.deptid = c.deptid
JOIN Feedback f ON c.courseid = f.courseid
GROUP BY d.deptname, c.title
ORDER BY avg_rating DESC
LIMIT 10;

# Distributed (use FDW remote table for node_b)
# Recreate remote_course_b to simulate node_b remote and re-run
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT d.deptname, c.title, COUNT(f.feedbackid) AS responses, ROUND(AVG(f.rating),2) AS avg_rating
FROM Department d
JOIN Course_ALL c ON d.deptid = c.deptid
JOIN Feedback_ALL f ON c.courseid = f.courseid
GROUP BY d.deptname, c.title
ORDER BY avg_rating DESC
LIMIT 10;

# Verification SQL (quick checks to paste & run)

# Quick checks
SELECT count(*) FROM Department;
SELECT count(*) FROM Instructor;
SELECT count(*) FROM Course;
SELECT count(*) FROM Student;
SELECT count(*) FROM Feedback;

SELECT * FROM EvaluationSummary ORDER BY CourseID;
SELECT * FROM node_a.course_a LIMIT 5;
SELECT * FROM node_b.course_b LIMIT 5;
SELECT * FROM remote_course_b LIMIT 5; -- if FDW set up

# Conclusion 

Through the series of tasks, I implemented both horizontal fragmentation and foreign data wrapper (FDW)–based database links to simulate physically distributed nodes. The system maintained referential integrity across departments, instructors, courses, and student feedback while allowing logical data separation between nodes.
By using two-phase commit (PREPARE/COMMIT PREPARED), I illustrated how distributed transactions can ensure atomicity and consistency even across multiple databases. The rollback and recovery tests further reinforced the importance of transaction coordination and recovery mechanisms in distributed systems.
The parallel query execution and ETL simulations provided insight into query optimization and workload scalability. I observed significant improvements in execution time when enabling multiple parallel workers, showing how parallelism reduces query latency in analytical workloads. Similarly, distributed query optimization via EXPLAIN ANALYZE and FDW settings 
(e.g., use_remote_estimate, fetch_size) highlighted how data movement and join strategies impact overall performance.
Concurrency control experiments using PostgreSQL’s pg_locks system catalog helped visualize locking conflicts and
 isolation behavior in real-time. Finally, benchmarking across centralized, parallel, and distributed setups showed
  that distributed architectures provide higher scalability and fault tolerance, albeit with slightly increased coordination overhead.
Overall, this project integrated concepts of database fragmentation, parallelism, replication, and consistency management
 within a realistic academic feedback scenario. It strengthened understanding of how modern distributed database systems 
 achieve scalability, reliability, and high availability—key pillars in advanced data management and cloud-based systems.








